{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce6aec97",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'LogisticRegression' from 'sklearn.ensemble' (/opt/anaconda3/envs/ag311/lib/python3.11/site-packages/sklearn/ensemble/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mensemble\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[32m      9\u001b[39m project_root = Path(\u001b[33m'\u001b[39m\u001b[33m..\u001b[39m\u001b[33m'\u001b[39m).resolve()\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mProject root:\u001b[39m\u001b[33m'\u001b[39m, project_root)\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'LogisticRegression' from 'sklearn.ensemble' (/opt/anaconda3/envs/ag311/lib/python3.11/site-packages/sklearn/ensemble/__init__.py)"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import LogisticRegression\n",
    "\n",
    "project_root = Path('..').resolve()\n",
    "print('Project root:', project_root)\n",
    "\n",
    "src_path = project_root / 'src'\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.append(str(src_path))\n",
    "\n",
    "from uais.supervised.train_fraud_supervised import FraudModelConfig, train_fraud_model\n",
    "from uais.utils.metrics import compute_classification_metrics\n",
    "from uais.utils.plotting import plot_roc_curve, plot_pr_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd51f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uais.data.load_fraud_data import load_fraud_data\n",
    "from uais.features.fraud_features import build_fraud_feature_table\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "df_raw_fraud = load_fraud_data()\n",
    "df_feats_fraud = build_fraud_feature_table(df_raw_fraud, 'Time', 'Amount', 'Class')\n",
    "\n",
    "X_fraud = df_feats_fraud.drop(columns=['Class'])\n",
    "y_fraud = df_feats_fraud['Class'].astype(int)\n",
    "\n",
    "Xf_train, Xf_test, yf_train, yf_test = train_test_split(\n",
    "    X_fraud, y_fraud, test_size=0.2, stratify=y_fraud, random_state=42\n",
    ")\n",
    "\n",
    "fraud_model = HistGradientBoostingClassifier(max_depth=4, learning_rate=0.1, max_iter=200, random_state=42)\n",
    "fraud_model.fit(Xf_train, yf_train)\n",
    "pf_test = fraud_model.predict_proba(Xf_test)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec6ec57",
   "metadata": {},
   "outputs": [],
   "source": [
    "cyber_path = project_root / 'data' / 'processed' / 'cyber' / 'unsw_nb15_features.parquet'\n",
    "df_cyber = pd.read_parquet(cyber_path)\n",
    "\n",
    "X_cyber = df_cyber.drop(columns=['label'])\n",
    "y_cyber = df_cyber['label'].astype(int)\n",
    "\n",
    "Xc_train, Xc_test, yc_train, yc_test = train_test_split(\n",
    "    X_cyber, y_cyber, test_size=0.2, stratify=y_cyber, random_state=42\n",
    ")\n",
    "\n",
    "cyber_model = HistGradientBoostingClassifier(max_depth=6, learning_rate=0.1, max_iter=200, random_state=42)\n",
    "cyber_model.fit(Xc_train, yc_train)\n",
    "pc_test = cyber_model.predict_proba(Xc_test)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f62492a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = min(len(pf_test), len(pc_test))\n",
    "fusion_features = np.stack([\n",
    "    np.pad(pf_test[:n], (0, 0)),\n",
    "    np.pad(pc_test[:n], (0, 0))\n",
    "], axis=1)\n",
    "\n",
    "y_fusion = ((pf_test[:n] > np.quantile(pf_test, 0.9)) |\n",
    "            (pc_test[:n] > np.quantile(pc_test, 0.9))).astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    fusion_features, y_fusion, test_size=0.3, stratify=y_fusion, random_state=42\n",
    ")\n",
    "\n",
    "meta_model = LogisticRegression()\n",
    "meta_model.fit(X_train, y_train)\n",
    "y_prob = meta_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "fusion_metrics = compute_classification_metrics(y_test, y_prob, threshold=0.5)\n",
    "print('Fusion meta-model metrics (toy example):')\n",
    "for k, v in fusion_metrics.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "plot_roc_curve(y_test, y_prob, title='Fusion ROC')\n",
    "plot_pr_curve(y_test, y_prob, title='Fusion PR')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ag311",
   "language": "python",
   "name": "ag311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

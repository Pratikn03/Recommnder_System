{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f428d78",
   "metadata": {},
   "source": [
    "# Sequence Anomaly Detection (LSTM/GRU)\n",
    "Synthetic behavior-like session sequences with padding/masking. Fast to run on CPU; no external data needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586c10be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: clean DataFrame to avoid missing-column/NaN errors\n",
    "import pandas as pd\n",
    "\n",
    "def clean_frame(df, target=None, numeric_expected=None, categorical_expected=None):\n",
    "    df = df.loc[:, ~df.columns.str.startswith('Unnamed')]\n",
    "    df = df.dropna(axis=1, how='all').copy()\n",
    "    numeric_expected = numeric_expected or []\n",
    "    categorical_expected = categorical_expected or []\n",
    "    for col in numeric_expected:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0.0\n",
    "    for col in categorical_expected:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 'missing'\n",
    "    num_cols = df.select_dtypes(include=['number']).columns\n",
    "    cat_cols = df.select_dtypes(exclude=['number']).columns\n",
    "    if len(num_cols):\n",
    "        df[num_cols] = df[num_cols].fillna(df[num_cols].median())\n",
    "    if len(cat_cols):\n",
    "        df[cat_cols] = df[cat_cols].fillna('missing')\n",
    "    if target:\n",
    "        if target not in df.columns:\n",
    "            raise KeyError(f\"Target '{target}' missing. Columns: {df.columns.tolist()}\")\n",
    "        df[target] = pd.to_numeric(df[target], errors='coerce').fillna(0).astype(int)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b255cbee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/pratik_n/Desktop/MyComputer/universal-anomaly-intelligence\n",
      "Using torch 2.9.1\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "project_root = Path('..').resolve()\n",
    "src_path = project_root / 'src'\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.append(str(src_path))\n",
    "\n",
    "from uais.sequence.build_sequences import build_sequences, pad_sequences\n",
    "from uais.sequence.train_lstm import train_lstm_classifier, predict_lstm\n",
    "from uais.sequence.train_gru import train_gru_classifier, predict_gru\n",
    "from uais.sequence.evaluate_sequence import evaluate_sequence_predictions\n",
    "from uais.explainability.sequence_explainer import sequence_saliency\n",
    "\n",
    "np.random.seed(42)\n",
    "import torch\n",
    "_ = torch.manual_seed(42)\n",
    "\n",
    "print('Project root:', project_root)\n",
    "print('Using torch', torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d16c9cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  session_id           timestamp  event_code   bytes_out  failed_login  label\n",
      "0         s0 2024-01-14 00:02:00           2   97.735204             0      0\n",
      "1         s0 2024-01-14 00:06:00           2  121.503590             0      0\n",
      "2         s0 2024-01-14 00:10:00           2  104.488128             0      0\n",
      "3         s0 2024-01-14 00:16:00           0  122.635356             0      0\n",
      "4         s0 2024-01-14 00:21:00           1  137.382580             1      0\n",
      "Events: 5807 Sequences: 320\n",
      "Positive sequences: 66\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic CERT-like session sequences (variable length)\n",
    "rng = np.random.default_rng(7)\n",
    "num_sessions = 320\n",
    "records = []\n",
    "for session_id in range(num_sessions):\n",
    "    length = int(rng.integers(8, 30))\n",
    "    base_ts = np.datetime64('2024-01-01') + np.timedelta64(int(rng.integers(0, 21)), 'D')\n",
    "    is_anomaly = bool(rng.random() < 0.2)\n",
    "    for step in range(length):\n",
    "        ts = base_ts + np.timedelta64(int(step * 5 + rng.integers(0, 4)), 'm')\n",
    "        event_code = int(rng.integers(0, 3))\n",
    "        bytes_out = float(rng.normal(120, 25))\n",
    "        failed = int(rng.binomial(1, 0.06))\n",
    "        if is_anomaly:\n",
    "            event_code = int(rng.integers(2, 4))\n",
    "            bytes_out += float(rng.normal(150, 40))\n",
    "            failed = int(rng.binomial(1, 0.25))\n",
    "        records.append({\n",
    "            'session_id': f's{session_id}',\n",
    "            'timestamp': pd.Timestamp(ts),\n",
    "            'event_code': event_code,\n",
    "            'bytes_out': max(bytes_out, 0.0),\n",
    "            'failed_login': failed,\n",
    "            'label': int(is_anomaly),\n",
    "        })\n",
    "\n",
    "seq_df = pd.DataFrame(records)\n",
    "seq_df = seq_df.sort_values(['session_id', 'timestamp']).reset_index(drop=True)\n",
    "print(seq_df.head())\n",
    "print('Events:', len(seq_df), 'Sequences:', seq_df['session_id'].nunique())\n",
    "print('Positive sequences:', seq_df.groupby('session_id')['label'].max().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03d4933e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded shape: (320, 40, 3)\n",
      "Mask shape: (320, 40)\n",
      "Feature dim: 3\n",
      "Positive ratio: 0.20625\n"
     ]
    }
   ],
   "source": [
    "# Build padded tensors + mask for the sequence models\n",
    "sequences, labels = build_sequences(\n",
    "    seq_df,\n",
    "    id_column='session_id',\n",
    "    time_column='timestamp',\n",
    "    target_column='label',\n",
    ")\n",
    "padded, mask = pad_sequences(sequences, max_len=40)\n",
    "labels = np.asarray(labels)\n",
    "\n",
    "print('Padded shape:', padded.shape)\n",
    "print('Mask shape:', mask.shape)\n",
    "print('Feature dim:', padded.shape[-1])\n",
    "print('Positive ratio:', labels.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f05cf25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-25 18:31:51,549 [INFO] uais.sequence.train_lstm: LSTM epoch 1 loss 0.7120\n",
      "2025-11-25 18:31:51,570 [INFO] uais.sequence.train_lstm: LSTM epoch 2 loss 0.6943\n",
      "2025-11-25 18:31:51,591 [INFO] uais.sequence.train_lstm: LSTM epoch 3 loss 0.6763\n",
      "2025-11-25 18:31:51,612 [INFO] uais.sequence.train_lstm: LSTM epoch 4 loss 0.6544\n",
      "2025-11-25 18:31:51,633 [INFO] uais.sequence.train_lstm: LSTM epoch 5 loss 0.6217\n",
      "2025-11-25 18:31:51,653 [INFO] uais.sequence.train_lstm: LSTM epoch 6 loss 0.5645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM train loss: 0.5645\n",
      "LSTM metrics:\n",
      "  roc_auc: 0.5000\n",
      "  pr_auc: 0.2000\n",
      "  f1: 0.0000\n",
      "  precision: 0.0000\n",
      "  recall: 0.0000\n",
      "  accuracy: 0.8000\n"
     ]
    }
   ],
   "source": [
    "# Train/test split and LSTM classifier\n",
    "X_train, X_test, mask_train, mask_test, y_train, y_test = train_test_split(\n",
    "    padded,\n",
    "    mask,\n",
    "    labels,\n",
    "    test_size=0.25,\n",
    "    stratify=labels,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "config = {'sequence': {'hidden_dim': 32, 'batch_size': 32, 'epochs': 6, 'lr': 1e-3}}\n",
    "\n",
    "lstm_model, lstm_loss = train_lstm_classifier(X_train, mask_train, y_train, config)\n",
    "lstm_scores = predict_lstm(lstm_model, X_test, mask_test)\n",
    "lstm_metrics = evaluate_sequence_predictions(y_test, lstm_scores)\n",
    "\n",
    "print('LSTM train loss:', round(lstm_loss, 4))\n",
    "print('LSTM metrics:')\n",
    "for k, v in lstm_metrics.items():\n",
    "    print(f\"  {k}: {v:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3caa7c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-25 18:31:51,684 [INFO] uais.sequence.train_gru: GRU epoch 1 loss 0.6795\n",
      "2025-11-25 18:31:51,707 [INFO] uais.sequence.train_gru: GRU epoch 2 loss 0.6445\n",
      "2025-11-25 18:31:51,731 [INFO] uais.sequence.train_gru: GRU epoch 3 loss 0.6111\n",
      "2025-11-25 18:31:51,771 [INFO] uais.sequence.train_gru: GRU epoch 4 loss 0.5684\n",
      "2025-11-25 18:31:51,804 [INFO] uais.sequence.train_gru: GRU epoch 5 loss 0.5275\n",
      "2025-11-25 18:31:51,828 [INFO] uais.sequence.train_gru: GRU epoch 6 loss 0.5071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU train loss: 0.5071\n",
      "GRU metrics:\n",
      "  roc_auc: 0.5000\n",
      "  pr_auc: 0.2000\n",
      "  f1: 0.0000\n",
      "  precision: 0.0000\n",
      "  recall: 0.0000\n",
      "  accuracy: 0.8000\n"
     ]
    }
   ],
   "source": [
    "# Lightweight GRU comparison (same hyperparams)\n",
    "gru_model, gru_loss = train_gru_classifier(X_train, mask_train, y_train, config)\n",
    "gru_scores = predict_gru(gru_model, X_test, mask_test)\n",
    "gru_metrics = evaluate_sequence_predictions(y_test, gru_scores)\n",
    "\n",
    "print('GRU train loss:', round(gru_loss, 4))\n",
    "print('GRU metrics:')\n",
    "for k, v in gru_metrics.items():\n",
    "    print(f\"  {k}: {v:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2cbdb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example score: 0.269\n",
      "Saliency (step -> avg magnitude):\n",
      "  t=0: 47.0562\n",
      "  t=1: 33.2935\n",
      "  t=2: 49.3933\n",
      "  t=3: 49.6646\n",
      "  t=4: 43.1149\n",
      "  t=5: 40.4860\n",
      "  t=6: 44.2769\n",
      "  t=7: 49.4137\n",
      "  t=8: 46.2818\n",
      "  t=9: 38.0497\n"
     ]
    }
   ],
   "source": [
    "# Simple saliency over time steps for one test sequence\n",
    "example_idx = 0\n",
    "saliency = sequence_saliency(X_test[example_idx:example_idx+1], mask_test[example_idx:example_idx+1])\n",
    "example_score = float(lstm_scores[example_idx])\n",
    "print('Example score:', round(example_score, 4))\n",
    "print('Saliency (step -> avg magnitude):')\n",
    "for step, score in saliency.items():\n",
    "    if mask_test[example_idx, step] > 0:\n",
    "        print(f\"  t={step}: {score:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-macos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
